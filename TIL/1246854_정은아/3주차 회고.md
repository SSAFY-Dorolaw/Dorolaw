# KPT 3주차 회고 - AI 기반 교통사고 과실 비율 산정 프로젝트

## 🟢 KEEP (유지할 점)

1. **로컬 환경에서 AI 모델 실행**

    - 초기에는 WSL + Docker 환경에서 실행을 시도했으나 설정 복잡성으로 인해 로컬 환경에서 직접 모델을 실행하는 방향으로 전환
    - 로컬에서 실행하니 설정이 간편하고 GPU 활용이 직관적이라 개발 효율성이 높아짐

2. **DetectoRS, VTN 등 다양한 모델 활용 경험**

    - DetectoRS(객체 탐지)와 VTN(비디오 분류)을 베이스라인으로 설정하여 교통사고 영상 분석 진행
    - 다양한 데이터셋에 파인튜닝하면서 모델 성능을 향상할 수 있는 가능성 확인

3. **Miniconda 기반 환경 관리**

    - AI 모델 실행을 위한 패키지 및 가상 환경 관리를 Miniconda로 수행
    - 일관성 있는 경로와 환경 설정(`C:\Users\SSAFY\ai-model\mmdetection`)으로 혼선을 줄임

4. **팀원 간 원활한 소통 및 이슈 공유**

    - 작업 진행 중 발생하는 문제나 막히는 부분을 빠르게 공유해 해결 방안을 함께 모색
    - 주·야간으로 다양한 커뮤니케이션 채널(오프라인 미팅, 메신저 등) 활용

5. **주변 자원(컨설턴트, 코치, 데이터 담당자) 적극 활용**
    - 막히는 부분이 있을 때 즉시 도움을 요청해 문제 해결 시간을 단축
    - 필요 정보를 얻기 위해 적극적으로 소통하고, 협업 가능한 부분을 빠르게 파악

---

## 🟠 PROBLEM (문제점 및 어려웠던 점)

1. **WSL + Docker 환경 설정 복잡성**

    - GPU 가속 문제 및 의존성 충돌 등으로 인해 프로젝트 초기에 많은 시간을 소모
    - 로컬 환경으로 전환하여 문제를 해결했지만, 처음 계획 대비 일정이 지연됨

2. **DetectoRS, VTN 모델 실행 시 의존성 충돌**

    - 버전 호환이 까다로워 MMDetection, MMCV 등 여러 라이브러리 버전을 조정해야 함
    - 모델 체크포인트 다운로드와 설치 과정에서 발생하는 크고 작은 이슈가 여럿 있었음

3. **소스 코드에 대한 이해 부족**

    - 기존 코드(DetectoRS, VTN, 변형된 학습 스크립트 등)의 구조와 동작 방식을 완전히 이해하지 못해 개발 속도가 느려짐
    - 코드 분석 시간이 충분하지 않아 향후 유지보수와 성능 최적화가 어려울 가능성

4. **진행 속도 지연 및 일정 재조정 필요**

    - 예상보다 AI 모델링, 데이터 준비, 기능 구현 등에 시간이 더 걸림
    - AI 분석 모델 외에도 추가 기능 요구사항이 확인되어 초기에 충분히 고려하지 못한 부분이 발생

5. **데이터 처리 및 모델 최적화 고민**
    - 교통사고 영상(블랙박스, CCTV)의 프레임 처리와 샘플링 전략 수립이 까다로움
    - 실시간 분석이 목표라면 모델 경량화(TensorRT, ONNX 변환 등)와 빠른 추론 속도가 중요

---

## 🟢 TRY (시도할 점 및 개선 방향)

1. **모델 최적화 및 가속화**

    - 실시간 분석 성능을 높이기 위해 TensorRT, ONNX 변환 등 다양한 방법을 시도
    - DetectoRS가 최적인지 YOLO v8 등 다른 모델과 비교 검토

2. **과실 비율 산정 모델 개발 심화**

    - 기존 사고 판례 데이터를 Transformer 기반 NLP 모델로 학습하여 문맥·상황별 과실 비율을 정밀하게 예측
    - 멀티모달(비전+텍스트) 형태로 결합해 영상 속 사건과 관련 판례·법규 정보를 동시에 고려

3. **코드 이해도 향상 및 학습**

    - DetectoRS, VTN 등 핵심 모델의 구조와 학습 파이프라인을 팀원들이 충분히 숙지
    - 코드 분석 문서화(예: 주요 함수, 클래스, 데이터 흐름 정리)로 신규 인원 투입 시 빠른 온보딩 가능

4. **사전 학습된 모델 실행 및 검증**

    - 먼저 베이스라인 모델(DetectoRS, VTN 등)로 사전 학습된 체크포인트를 실행·검증
    - 실행 과정에서 발생하는 에러/워닝을 정리하고 즉각 해결책을 찾는 루틴 확립

5. **AI 모델링 일정 재조정 및 기능 우선순위 설정**

    - 현재 진행 상황을 고려해 일정과 목표를 다시 설정하고, 긴급도가 높은 기능부터 구현
    - 중간 리뷰(예: 1~2주 간격)를 통해 계획 대비 진행 상황을 점검하고 문제점을 빠르게 조정

6. **환경 자동화 및 배포 가능성 검토**
    - 로컬 환경에서도 쉽게 재현할 수 있도록 conda 환경 설정 스크립트, requirements 파일 정비
    - 추후 API 형태로 서비스화(FastAPI, Flask 등)를 고려해 Docker를 다시 검토하되, 이전 문제점(의존성, GPU 설정 등)을 사전에 해결할 수 있는지 확인
